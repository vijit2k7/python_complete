{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "pd.set_option('display.max_columns',100) #to display all columns below\n",
    "pd.set_option('display.max_rows',130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./data/application_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-532f62cf97a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/application_data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'./data/application_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"./data/application_data.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **As there are 122 columns it's difficult to do any meaningful analysis on all of them. Let's identify the best 20-25 columns for further analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**While exploring the data set, we shall follow the below order to arrive at the final set of columns for further analysis**\n",
    " 1. Remove the columns with more than 40% missing values, unless there are exceptions\n",
    " 2. Handle missing values in the rest of the variables\n",
    " 3. Check if all the variables left have the correct datatypes\n",
    " 4. Check for any outlier values and handle them accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CLEANING AND ANALYSIS OF DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a list of variables with more than 40% missing values\n",
    "highnull_list = df.isnull().sum()/307511\n",
    "print(highnull_list[highnull_list>0.4].sort_values().count())\n",
    "highnull_list[highnull_list>0.4].sort_values().index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Out of the 49 variables that have high missing values there are 47 variables that deal with details related to the premises in which the client resides. Let's drop those variables for now. \n",
    " \n",
    "- There are two more variables- 'OWN_CAR_AGE' & 'EXT_SOURCE_1'. As 'EXT_SOURCE_1' deals with rating an external agency has given to our borrower, let's keep the variable and handle the missing values as deemed fit and drop the variable 'OWN_CAR_AGE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns with a high % of missing values\n",
    "\n",
    "df.drop(columns = ['EMERGENCYSTATE_MODE', 'TOTALAREA_MODE',\n",
    "       'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BEGINEXPLUATATION_AVG',\n",
    "       'YEARS_BEGINEXPLUATATION_MODE', 'FLOORSMAX_MEDI', 'FLOORSMAX_MODE',\n",
    "       'FLOORSMAX_AVG', 'HOUSETYPE_MODE', 'LIVINGAREA_MODE',\n",
    "       'LIVINGAREA_AVG', 'LIVINGAREA_MEDI', 'ENTRANCES_MEDI',\n",
    "       'ENTRANCES_MODE', 'ENTRANCES_AVG', 'APARTMENTS_MEDI',\n",
    "       'APARTMENTS_MODE', 'APARTMENTS_AVG', 'WALLSMATERIAL_MODE',\n",
    "       'ELEVATORS_AVG', 'ELEVATORS_MODE', 'ELEVATORS_MEDI',\n",
    "       'NONLIVINGAREA_MODE', 'NONLIVINGAREA_AVG', 'NONLIVINGAREA_MEDI',\n",
    "       'BASEMENTAREA_AVG', 'BASEMENTAREA_MODE',\n",
    "       'BASEMENTAREA_MEDI', 'LANDAREA_MEDI', 'LANDAREA_MODE',\n",
    "       'LANDAREA_AVG', 'OWN_CAR_AGE', 'YEARS_BUILD_MEDI',\n",
    "       'YEARS_BUILD_MODE', 'YEARS_BUILD_AVG', 'FLOORSMIN_MEDI',\n",
    "       'FLOORSMIN_AVG', 'FLOORSMIN_MODE', 'LIVINGAPARTMENTS_MODE',\n",
    "       'LIVINGAPARTMENTS_MEDI', 'LIVINGAPARTMENTS_AVG',\n",
    "       'FONDKAPREMONT_MODE', 'NONLIVINGAPARTMENTS_AVG',\n",
    "       'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAPARTMENTS_MODE',\n",
    "       'COMMONAREA_MEDI', 'COMMONAREA_MODE', 'COMMONAREA_AVG'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rearranging the columns according to the following groups for easy access**\n",
    "-   Customer info and rating (ID, Target, Ext_source...)\n",
    "-   Socio-demographics of the customer (Gender, Employment, Education, Family, rating of the region/city)\n",
    "-   Social circle of the customer \n",
    "-   Bank related info (Documents etc.,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['SK_ID_CURR','TARGET','EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','NAME_CONTRACT_TYPE',\n",
    "         'CODE_GENDER','NAME_EDUCATION_TYPE','DAYS_BIRTH','DAYS_EMPLOYED','ORGANIZATION_TYPE','OCCUPATION_TYPE','NAME_INCOME_TYPE',\n",
    "         'NAME_FAMILY_STATUS','CNT_FAM_MEMBERS','CNT_CHILDREN',\n",
    "         'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n",
    "         'FLAG_OWN_REALTY', 'NAME_HOUSING_TYPE','FLAG_OWN_CAR', \n",
    "         'REGION_POPULATION_RELATIVE','REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY',\n",
    "         'OBS_30_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "         'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START',\n",
    "         'NAME_TYPE_SUITE', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'FLAG_MOBIL','FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE','FLAG_PHONE', 'FLAG_EMAIL',\n",
    "         'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY','REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY',\n",
    "         'DAYS_LAST_PHONE_CHANGE','FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4','FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7','FLAG_DOCUMENT_8', \n",
    "         'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10','FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13','FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n",
    "         'FLAG_DOCUMENT_16','FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19','FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21',\n",
    "         'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "         'AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChecKing for % of null values in the rest of the variables - in ascending order\n",
    "100*df.isnull().sum().sort_values()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that the following variables still have missing values\n",
    "-  Categorical - OCCUPATION_TYPE & NAME_TYPE_SUITE\n",
    "-  Numerical - EXT_SOURCE (1,2 &3), AMT_REQ_CREDIT_BUREAU( Hour, Day, Week, Month, Quarter and Year),  SOCIAL_CIRCLE (observed & defaulted), AMT_GOODS_PRICE, AMT_ANNUITY, CNT_FAM_MEMBERS and DAYS_LAST_PHONE_CHANGE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling categorical variables\n",
    "- **OCCUPATION_TYPE** - IN this case we see there are around 30% missing values so lets analyse why are they missing and can we replace it with the mode value ie., 'Laborers'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the null columns and try to find some relation as to why those columns are missing the data.\n",
    "df[df['OCCUPATION_TYPE'].isnull()].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can clearly see that there seems to be some relation with Income_Type and Organization_Type\n",
    "# First, let's check how many values of Pensioner are present in the dataframe\n",
    "\n",
    "df['NAME_INCOME_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's check for how many values of \"Pensioner\" in Income_Type we get a null value in Occupation_Type\n",
    "\n",
    "df[df['OCCUPATION_TYPE'].isnull()]['NAME_INCOME_TYPE'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Therefore we have a MNAR (Missing Not at Random) in Occupation_Type.\n",
    "-  It's possible that the values are missing for those who are retired or working in fields that cannot be easily described.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SOLUTION** - \n",
    "We can't replace the null values directly with 'Laborers' (mode) as it will wrongly inflate the numbers of laborers.\n",
    "Instead, it's better to replace null values for \"Pensioners\" it with a new category called **'Retired'** and replace rest of the null values with **'Others'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a new 'Retired' value for pensioners in income_type\n",
    "df.loc[df['NAME_INCOME_TYPE']=='Pensioner','OCCUPATION_TYPE']='Retired'\n",
    "df['OCCUPATION_TYPE']=df['OCCUPATION_TYPE'].fillna('Others')\n",
    "df['OCCUPATION_TYPE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **NAME_TYPE_SUITE** - There are 4% missing values. So, it's better to impute the missing values with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME_TYPE_SUITE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the most frequent value in the variable is \"Unaccompanied\", let's replace the null values with that\n",
    "df['NAME_TYPE_SUITE'] = df.NAME_TYPE_SUITE.fillna(\"Unaccompanied\")\n",
    "df['NAME_TYPE_SUITE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling numerical variables\n",
    "- **EXT_SOURCE_1** - In this case we see there are around 56% missing values\n",
    "- **EXT_SOURCE_2** - In this case we see there are around 0.2% missing values\n",
    "- **EXT_SOURCE_3** - In this case we see there are around 20% missing values\n",
    "    - so lets analyse why are they missing and what can be done about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,[\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 4))\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(df['EXT_SOURCE_1'])\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot(df['EXT_SOURCE_2'])\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot(df['EXT_SOURCE_3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.EXT_SOURCE_1.isnull()].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.EXT_SOURCE_2.isnull()].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.EXT_SOURCE_3.isnull()].sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **OBSERVATION** - \n",
    "- It seems that the values are missing completely at random (MCAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SOLUTION** - \n",
    "It is better to drop the rows that have mising values in all three variables and only keep those rows that have the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = df_n[~df_n.EXT_SOURCE_1.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = df_n[~df_n.EXT_SOURCE_2.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = df_n[~df_n.EXT_SOURCE_3.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Thus we get a new dataframe that has 35% of the rows ofthe original dataframe to work with these values\n",
    "df_n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **AMT_REQ_CREDIT_BUREAU** - 13.5% of the customers don't have the detials pertaining to these variables. \n",
    "    - so let's analyse why are they missing and what can be done about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,[\"AMT_REQ_CREDIT_BUREAU_HOUR\",\"AMT_REQ_CREDIT_BUREAU_DAY\",\"AMT_REQ_CREDIT_BUREAU_WEEK\",\"AMT_REQ_CREDIT_BUREAU_MON\",\"AMT_REQ_CREDIT_BUREAU_QRT\",\"AMT_REQ_CREDIT_BUREAU_YEAR\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 4))\n",
    "plt.subplot(1,6,1)\n",
    "sns.boxplot(df['AMT_REQ_CREDIT_BUREAU_HOUR'])\n",
    "plt.subplot(1,6,2)\n",
    "sns.boxplot(df['AMT_REQ_CREDIT_BUREAU_DAY'])\n",
    "plt.subplot(1,6,3)\n",
    "sns.boxplot(df['AMT_REQ_CREDIT_BUREAU_WEEK'])\n",
    "plt.subplot(1,6,4)\n",
    "sns.boxplot(df['AMT_REQ_CREDIT_BUREAU_MON'])\n",
    "plt.subplot(1,6,5)\n",
    "sns.boxplot(df['AMT_REQ_CREDIT_BUREAU_QRT'])\n",
    "plt.subplot(1,6,6)\n",
    "sns.boxplot(df['AMT_REQ_CREDIT_BUREAU_YEAR'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SOLUTION** - \n",
    "Since outliers are present we will take median as the metric and hence substitute 0.00 for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['AMT_REQ_CREDIT_BUREAU_HOUR','AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']]=df[['AMT_REQ_CREDIT_BUREAU_HOUR','AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']].fillna(0.00)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **SOCIAL_CIRCLE_ (observed & defaulted)** - 0.33% of the customers don't have the detials pertaining to these variables. \n",
    "    - so lets analyse why are they missing and what can be done about them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,[\"OBS_30_CNT_SOCIAL_CIRCLE\",\"DEF_30_CNT_SOCIAL_CIRCLE\",\"OBS_60_CNT_SOCIAL_CIRCLE\",\"DEF_60_CNT_SOCIAL_CIRCLE\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,4])\n",
    "plt.subplot(1,4,1)\n",
    "sns.boxplot(df['OBS_30_CNT_SOCIAL_CIRCLE'])\n",
    "plt.subplot(1,4,2)\n",
    "sns.boxplot(df['DEF_30_CNT_SOCIAL_CIRCLE'])\n",
    "plt.subplot(1,4,3)\n",
    "sns.boxplot(df['OBS_60_CNT_SOCIAL_CIRCLE'])\n",
    "plt.subplot(1,4,4)\n",
    "sns.boxplot(df['DEF_60_CNT_SOCIAL_CIRCLE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **OBSERVATION** - \n",
    "The values seem to be missing at random, and since there are only 0.33% of the dataset with missing values we can either drop them or impute the median value.\n",
    "#### **SOLUTION** - \n",
    "Since outliers are present we will take median as the metric and hence substitute 0.00 for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['OBS_30_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE']]=df[['OBS_30_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE']].fillna(0.00)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **AMT_GOODS_PRICE** - o.09% of the customers don't have the detials pertaining to these variables. \n",
    "- **AMT_ANNUITY**     - 0.003% of the customers don't have the detials pertaining to these variables.\n",
    "- **CNT_FAM_MEMBERS** - 0.00065% of the customers don't have the detials pertaining to these variables.\n",
    "    - As the % of missing values are negligible let's drop the rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~df.CNT_FAM_MEMBERS.isnull()==True]\n",
    "df=df[~df.AMT_GOODS_PRICE.isnull()==True]\n",
    "df=df[~df.AMT_ANNUITY.isnull()==True]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values().tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling variables with incorrect data types\n",
    "####  Let's apply a logic that if a column has unique values around 40, then that variable can be considered to be a categorical variable else it can be considered as a continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **We will convert the below columns data types-**\n",
    "- **CNT_CHILDREN** - From int64 to categorical.\n",
    "- **CNT_FAM_MEMBERS** - From float64 to categorical.\n",
    "- **REGION_RATINGs** - From int64 to categorical.\n",
    "- **FLAG_DOCUMENTs** - From int64 to categorical.\n",
    "- **REGION-related** - From int64 to categorical.\n",
    "- **HOUR_APPR_PROCESS_START** - From int64 to categorical.\n",
    "- **DAYS_BIRTH** - From int64 to float64.\n",
    "- **DAYS_EMPLOYED** - From int64 to float64.\n",
    "- **TARGET** - From int64 to categorical\n",
    "- **SK_ID_CURR** - From int64 to categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['REGION_RATING_CLIENT'] = df['REGION_RATING_CLIENT'].astype(str)\n",
    "df['REGION_RATING_CLIENT_W_CITY'] = df['REGION_RATING_CLIENT_W_CITY'].astype(str)\n",
    "df['HOUR_APPR_PROCESS_START'] = df['HOUR_APPR_PROCESS_START'].astype(int)\n",
    "df['DAYS_BIRTH'] = df['DAYS_BIRTH'].astype(float)\n",
    "df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].astype(float)\n",
    "df[\"REG_REGION_NOT_LIVE_REGION\"] = df[\"REG_REGION_NOT_LIVE_REGION\"].astype(str)\n",
    "df[\"REG_REGION_NOT_WORK_REGION\"] = df[\"REG_REGION_NOT_WORK_REGION\"].astype(str)\n",
    "df[\"LIVE_REGION_NOT_WORK_REGION\"] = df[\"LIVE_REGION_NOT_WORK_REGION\"].astype(str)\n",
    "df[\"REG_CITY_NOT_LIVE_CITY\"] = df[\"REG_CITY_NOT_LIVE_CITY\"].astype(str)\n",
    "df[\"REG_CITY_NOT_WORK_CITY\"] = df[\"REG_CITY_NOT_WORK_CITY\"].astype(str)\n",
    "df[\"LIVE_CITY_NOT_WORK_CITY\"] = df[\"LIVE_CITY_NOT_WORK_CITY\"].astype(str)\n",
    "df[\"FLAG_MOBIL\"] = df[\"FLAG_MOBIL\"].astype(str)\n",
    "df[\"FLAG_EMP_PHONE\"] = df[\"FLAG_EMP_PHONE\"].astype(str)\n",
    "df[\"FLAG_WORK_PHONE\"] = df[\"FLAG_WORK_PHONE\"].astype(str)\n",
    "df[\"FLAG_CONT_MOBILE\"] = df[\"FLAG_CONT_MOBILE\"].astype(str)\n",
    "df[\"FLAG_PHONE\"] = df[\"FLAG_PHONE\"].astype(str)\n",
    "df[\"FLAG_EMAIL\"] = df[\"FLAG_EMAIL\"].astype(str)\n",
    "df[\"SK_ID_CURR\"] = df[\"SK_ID_CURR\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_2\"] = df[\"FLAG_DOCUMENT_2\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_3\"] = df[\"FLAG_DOCUMENT_3\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_4\"] = df[\"FLAG_DOCUMENT_4\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_5\"] = df[\"FLAG_DOCUMENT_5\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_6\"] = df[\"FLAG_DOCUMENT_6\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_7\"] = df[\"FLAG_DOCUMENT_7\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_8\"] = df[\"FLAG_DOCUMENT_8\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_9\"] = df[\"FLAG_DOCUMENT_9\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_10\"] = df[\"FLAG_DOCUMENT_10\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_11\"] = df[\"FLAG_DOCUMENT_11\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_12\"] = df[\"FLAG_DOCUMENT_12\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_13\"] = df[\"FLAG_DOCUMENT_13\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_14\"] = df[\"FLAG_DOCUMENT_14\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_15\"] = df[\"FLAG_DOCUMENT_15\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_16\"] = df[\"FLAG_DOCUMENT_16\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_17\"] = df[\"FLAG_DOCUMENT_17\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_18\"] = df[\"FLAG_DOCUMENT_18\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_19\"] = df[\"FLAG_DOCUMENT_19\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_20\"] = df[\"FLAG_DOCUMENT_20\"].astype(str)\n",
    "df[\"FLAG_DOCUMENT_21\"] = df[\"FLAG_DOCUMENT_21\"].astype(str)\n",
    "df['TARGET']=df['TARGET'].apply(lambda x : 'Yes' if x==1 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting DAYS_BIRTH and DAYS_EMPLOYED to years\n",
    "df['AGE'] = abs(df['DAYS_BIRTH'])/365\n",
    "df['YRS_EMPLOYED'] = abs(df['DAYS_EMPLOYED'])/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['AGE','YRS_EMPLOYED']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CHECKING OUTLIERS FOR DIFFERENT NUMERIC VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,20])\n",
    "plt.subplot(4,4,1)\n",
    "sns.boxplot(df.AMT_INCOME_TOTAL)\n",
    "plt.subplot(4,4,2)\n",
    "sns.boxplot(df.AMT_CREDIT)\n",
    "plt.subplot(4,4,3)\n",
    "sns.boxplot(df.AMT_ANNUITY)\n",
    "plt.subplot(4,4,4)\n",
    "sns.boxplot(df.AMT_GOODS_PRICE)\n",
    "plt.subplot(4,4,5)\n",
    "sns.boxplot(df.AGE)\n",
    "plt.subplot(4,4,6)\n",
    "sns.boxplot(df.YRS_EMPLOYED)\n",
    "plt.subplot(4,4,7)\n",
    "sns.boxplot(df.OBS_30_CNT_SOCIAL_CIRCLE)\n",
    "plt.subplot(4,4,8)\n",
    "sns.boxplot(df.DEF_30_CNT_SOCIAL_CIRCLE)\n",
    "plt.subplot(4,4,9)\n",
    "sns.boxplot(df.OBS_60_CNT_SOCIAL_CIRCLE)\n",
    "plt.subplot(4,4,10)\n",
    "sns.boxplot(df.DEF_60_CNT_SOCIAL_CIRCLE)\n",
    "plt.subplot(4,4,11)\n",
    "sns.boxplot(df.AMT_REQ_CREDIT_BUREAU_HOUR)\n",
    "plt.subplot(4,4,12)\n",
    "sns.boxplot(df.AMT_REQ_CREDIT_BUREAU_DAY)\n",
    "plt.subplot(4,4,13)\n",
    "sns.boxplot(df.AMT_REQ_CREDIT_BUREAU_WEEK)\n",
    "plt.subplot(4,4,14)\n",
    "sns.boxplot(df.AMT_REQ_CREDIT_BUREAU_MON)\n",
    "plt.subplot(4,4,15)\n",
    "sns.boxplot(df.AMT_REQ_CREDIT_BUREAU_QRT)\n",
    "plt.subplot(4,4,16)\n",
    "sns.boxplot(df.AMT_REQ_CREDIT_BUREAU_YEAR)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,6])\n",
    "sns.boxplot(df.AMT_INCOME_TOTAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ANALYSIS FOR THE OUTLIERS**\n",
    "\n",
    "#### 1.AMT_INCOME_TOTAL ####\n",
    "- There are many points which lie outside the quartile ranges and hence this column contains a lot of outliers\n",
    "- Calculating the number of outliers-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.AMT_INCOME_TOTAL.quantile(0.25)\n",
    "Q3 = df.AMT_INCOME_TOTAL.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "Q3+IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating the number of outliers for amount_total_income column by calculating the IQR\n",
    "len(df.AMT_INCOME_TOTAL[(df.AMT_INCOME_TOTAL > (Q3 + 1.5 * IQR))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMOVING THE OUTLIERS FOR BETTER ANALYSIS\n",
    "df=df[~(df.AMT_INCOME_TOTAL > 2*(Q3 + 1.5 * IQR))]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - There are around 5568 outliers in this column and what we observe is few of them have income over 4 million which is much greater than the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.AMT_CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.AMT_CREDIT.quantile(0.25)\n",
    "Q3 = df.AMT_CREDIT.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating the number of outliers for amount_total_income column by calculating the IQR\n",
    "len(df.AMT_CREDIT[(df.AMT_CREDIT > (Q3 + 1.5 * IQR))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMOVING THE OUTLIERS FOR BETTER ANALYSIS\n",
    "df=df[~(df.AMT_CREDIT > (Q3 + 1.5 * IQR))]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.DAYS_EMPLOYED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.YRS_EMPLOYED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.YRS_EMPLOYED.quantile(0.25)\n",
    "Q3 = df.YRS_EMPLOYED.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "Q3+1.5*IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating the number of outliers for amount_total_income column by calculating the IQR\n",
    "len(df[(df.YRS_EMPLOYED > 2*(Q3 + 1.5 * IQR))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.YRS_EMPLOYED > 2*(Q3 + 1.5 * IQR))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATION AND ANALYSIS** - Here we see that for all the retired people who are getting **pensions** the DAYS_EMPLOYED is more than 1000 years which is wrong but we can't drop those values hence we will replace those VALUES with the max cap value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replacing the outliers with max value of Days_Employed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BINNING DIFFERENT VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.HOUR_APPR_PROCESS_START.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### binning HOUR_APPR_PROCESS_START variable according to morning,afternoon,evening and night\n",
    "### 5-12 morning,12-18 afternoon,18-24 evening,0-5 night\n",
    "df['Hourly_Bucket'] = pd.cut(df.HOUR_APPR_PROCESS_START, bins = [-1,5,12,18,24], labels = [\"night\", \"morning\", \"afternoon\", \"evening\"])\n",
    "df['Hourly_Bucket'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.AGE.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### binning DAYS_BIRTH variable according to young, adults , senior_citizen\n",
    "### 20-33 young,33-55 adults,55-75 senior citizen\n",
    "df['Age_Bucket'] = pd.cut(df.AGE, bins = [20,33,55,75], labels = [\"young\", \"adults\", \"senior_citizen\"])\n",
    "df['Age_Bucket'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.AMT_INCOME_TOTAL.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### binning AMT_INCOME_TOTAL variable according to \"low\", \"lower-middle\", \"upper-middle\",\"high\"\n",
    "### 20-33 young,33-55 adults,55-75 senior citizen\n",
    "maximum=max(df.AMT_INCOME_TOTAL)\n",
    "df['Income_Bucket'] = pd.cut(df.AMT_INCOME_TOTAL, bins = [0,100000,200000,450000,maximum], labels = [\"low\", \"lower-middle\", \"upper-middle\",\"high\"])\n",
    "df['Income_Bucket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of children\n",
    "df.CNT_CHILDREN.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning CNT_CHILDREN variable according to \"No children\", \"1-Child\", \"2-Children\",\"3-5 Children\", \"More than 5 children\"\n",
    "\n",
    "df['Num-Children'] = pd.cut(df.CNT_CHILDREN, bins = [-1,0,1,2,5,12], labels = [\"No children\", \"1-Child\", \"2-Children\",\"3-5 Children\", \"More than 5 children\"])\n",
    "df['Num-Children'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of family members\n",
    "\n",
    "df.CNT_FAM_MEMBERS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning CNT_FAM_MEMBERS variable according to \"1 member\",\"2 members\", \"3 members\", \"4 members\", \"More than 4 members\"\n",
    "\n",
    "df['Size_Family'] = pd.cut(df.CNT_FAM_MEMBERS, bins = [0,1,2,3,4,12], labels = [\"1 member\", \"2 members\", \"3 members\",\"4 members\", \"More than 4 members\"])\n",
    "df['Size_Family'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the columns that may not be helphul in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['DAYS_BIRTH', 'DAYS_EMPLOYED','DAYS_REGISTRATION',\n",
    "       'DAYS_ID_PUBLISH', 'FLAG_MOBIL', 'FLAG_EMP_PHONE',\n",
    "       'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
    "       'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n",
    "       'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY',\n",
    "       'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY',\n",
    "       'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n",
    "       'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n",
    "       'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n",
    "       'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n",
    "       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n",
    "       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n",
    "       'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Imbalance** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*df.TARGET.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dividing the target variable into 2 datasets ie 0 and 1.\n",
    "df_1 = df[df['TARGET']=='Yes']\n",
    "df_0 = df[df['TARGET']=='No']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Finding Correlation and Plotting HeatMaps Between Different variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,8])\n",
    "sns.heatmap(df_0.corr(),annot=True,cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,8])\n",
    "sns.heatmap(df_1.corr(),annot=True,cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TOP 10 CORRELATED VARIABLES FOR BOTH DEFAULT AND NON-DEFAULT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "corr = df_1.corr()\n",
    "corr_df_1 = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "corr_df_1 = corr_df_1.unstack().reset_index().dropna(subset = [0])\n",
    "corr_df_1.columns = ['VAR1', 'VAR2', 'Correlation_Value']\n",
    "corr_df_1['Corr_abs'] = abs(corr_df_1['Correlation_Value'])\n",
    "corr_df_1.sort_values(by = \"Corr_abs\", ascending =False, inplace = True)\n",
    "corr_df_1.iloc[0:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_0.corr()\n",
    "corr_df = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "corr_df = corr_df.unstack().reset_index().dropna(subset = [0])\n",
    "corr_df.columns = ['VAR1', 'VAR2', 'Correlation_Value']\n",
    "corr_df['Corr_abs'] = abs(corr_df['Correlation_Value'])\n",
    "corr_df.sort_values(by = \"Corr_abs\", ascending =False, inplace = True)\n",
    "corr_df.iloc[0:23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **UNIVARIATE AND BIVARIATE**\n",
    "\n",
    "Univariate:\n",
    "    - Continuous Variable\n",
    "    - Categorical Variable\n",
    "\n",
    "Bivariate Anlysis:\n",
    "    - Conti-Conti\n",
    "    - Categorical-Categorical\n",
    "    - Conti-Categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,6])\n",
    "sns.distplot(df_1['AMT_CREDIT'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['AMT_CREDIT'], hist = False, label = 'Non-Defaulted')\n",
    "sns.distplot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - From the above curve we can say that for Amount Credit both the curves are almost **normally distributed** for both Defaulted and Non-Defaulted targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=[12,6])\n",
    "sns.distplot(df_1['REGION_POPULATION_RELATIVE'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['REGION_POPULATION_RELATIVE'], hist = False, label = 'Non-Defaulted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,5])\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.distplot(df_1['EXT_SOURCE_1'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['EXT_SOURCE_1'], hist = False, label = 'Non-Defaulted')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.distplot(df_1['EXT_SOURCE_2'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['EXT_SOURCE_2'], hist = False, label = 'Non-Defaulted')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.distplot(df_1['EXT_SOURCE_3'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['EXT_SOURCE_3'], hist = False, label = 'Non-Defaulted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - With the Extenal rating of 0.5 and above there is more chance of the customer paying back the loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,8])\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.distplot(df_1['OBS_30_CNT_SOCIAL_CIRCLE'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['OBS_30_CNT_SOCIAL_CIRCLE'], hist = False, label = 'Non-Defaulted')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.distplot(df_1['DEF_30_CNT_SOCIAL_CIRCLE'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['DEF_30_CNT_SOCIAL_CIRCLE'], hist = False, label = 'Non-Defaulted')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.distplot(df_1['OBS_60_CNT_SOCIAL_CIRCLE'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['OBS_60_CNT_SOCIAL_CIRCLE'], hist = False, label = 'Non-Defaulted')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.distplot(df_1['DEF_60_CNT_SOCIAL_CIRCLE'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['DEF_60_CNT_SOCIAL_CIRCLE'], hist = False, label = 'Non-Defaulted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - There is a small likelyhood that a customer who has a defaulter in his social circle might defalut as well. But this probability is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,8])\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.distplot(df_1['AMT_REQ_CREDIT_BUREAU_HOUR'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['AMT_REQ_CREDIT_BUREAU_HOUR'], hist = False, label = 'Non-Defaulted')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.distplot(df_1['AMT_REQ_CREDIT_BUREAU_DAY'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['AMT_REQ_CREDIT_BUREAU_DAY'], hist = False, label = 'Non-Defaulted')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.distplot(df_1['AMT_REQ_CREDIT_BUREAU_WEEK'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['AMT_REQ_CREDIT_BUREAU_WEEK'], hist = False, label = 'Non-Defaulted')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.distplot(df_1['AMT_REQ_CREDIT_BUREAU_MON'], hist = False, label = 'Defaulted')\n",
    "sns.distplot(df_0['AMT_REQ_CREDIT_BUREAU_MON'], hist = False, label = 'Non-Defaulted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - There is not much that we can gather from this inforamtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,4])\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Non-Default\")\n",
    "sns.boxplot(df_0.AGE)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Default\")\n",
    "sns.boxplot(df_1.AGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCUSION** - From the above analysis we can observe 2 points-\n",
    "    1. Median(Non-Default)>Median(Default)\n",
    "    2. People who are young tends to default more in comparison to people who are older."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### analysing the days_employed column\n",
    "### uni-continuous\n",
    "\n",
    "plt.figure(figsize=[20,4])\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Non-Default\")\n",
    "sns.boxplot(df_0[df_0.YRS_EMPLOYED<60].YRS_EMPLOYED)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Default\")\n",
    "sns.boxplot(df_1[df_1.YRS_EMPLOYED<60].YRS_EMPLOYED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uni-Categorical\n",
    "\n",
    "## analysis on the age bucket which was created\n",
    "plt.figure(figsize = (10, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['Age_Bucket'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "sns.countplot(df_0['Age_Bucket'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION**\n",
    " - Young people(age between 20-33) Around 4000 young people tend to default.\n",
    " - Adults(age between 33-55) Most defaults are from this age group.\n",
    " -Senior (age between 55-75) Least defaults are from this age group.\n",
    " \n",
    " - **The above analysis shows that our target should be the age group between 33-55 as these people are most vulnerable candidates who can default maybe because they are already supporting their parents,children and maybe not settled yet and hence can be considered hot targets.**\n",
    " - **The senior citizen are less likely to default as maybe they have pensions and savings from their earnings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uni-Categorical\n",
    "\n",
    "## analysis on the income bucket which was created\n",
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['NAME_INCOME_TYPE'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['NAME_INCOME_TYPE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - Most of the people defaulted belong to the Working class,whereas State servants are defaulted the least(As they have to keep clean records for their status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis on the Occupation_type bucket which was created\n",
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['OCCUPATION_TYPE'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['OCCUPATION_TYPE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - A retired person is more likely to pay back the loan and laborers are likely to default more. Those whose occupation type is \"Drivers\" are also one of the likely candidates to defalut more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['NAME_FAMILY_STATUS'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['NAME_FAMILY_STATUS'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - Married people are the highest in the default category wheras widowed are the lowest who are getting defaulted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['NAME_CONTRACT_TYPE'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['NAME_CONTRACT_TYPE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['WEEKDAY_APPR_PROCESS_START'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['WEEKDAY_APPR_PROCESS_START'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['FLAG_OWN_CAR'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['FLAG_OWN_CAR'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['FLAG_OWN_REALTY'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['FLAG_OWN_REALTY'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['NAME_HOUSING_TYPE'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['NAME_HOUSING_TYPE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['Num-Children'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['Num-Children'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['Size_Family'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['Size_Family'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(df_1['REGION_RATING_CLIENT'])\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['REGION_RATING_CLIENT'])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_1['REGION_RATING_CLIENT_W_CITY'])\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title(\"Non-Default\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_0['REGION_RATING_CLIENT_W_CITY'])\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BIVARIATE ANALYSIS**\n",
    "\n",
    "#### **1.CONTI-CONTI ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter\n",
    "\n",
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.scatterplot(df_1['AGE'],df_1[df_1.YRS_EMPLOYED<60].YRS_EMPLOYED)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "sns.scatterplot(df_0['AGE'], df_0[df_0.YRS_EMPLOYED<60].YRS_EMPLOYED)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter\n",
    "\n",
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.lineplot(x='AMT_GOODS_PRICE',y='AMT_CREDIT',data=df_1)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "sns.lineplot(df_0['AMT_GOODS_PRICE'], df_0['AMT_CREDIT'])\n",
    "plt.sow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - From the above curve we can establish that there is a **linear relationship** between AMT_CREDIT AND AMT_GOODS_PRICE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter\n",
    "\n",
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.scatterplot(x='AMT_INCOME_TOTAL',y='AMT_CREDIT',data=df_1)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "sns.scatterplot(x='AMT_INCOME_TOTAL',y='AMT_CREDIT',data=df_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter\n",
    "\n",
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.scatterplot(x='AMT_GOODS_PRICE',y='AMT_INCOME_TOTAL',data=df_1)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "sns.scatterplot(x='AMT_GOODS_PRICE',y='AMT_INCOME_TOTAL',data=df_0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter\n",
    "\n",
    "plt.figure(figsize = (15, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.scatterplot(x='REGION_POPULATION_RELATIVE',y='AMT_INCOME_TOTAL',data=df_1)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non-Default\")\n",
    "sns.scatterplot(x='REGION_POPULATION_RELATIVE',y='AMT_INCOME_TOTAL',data=df_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - From the above curve we can establish that there is relationship between people defaulting,population density and income ie\n",
    "\n",
    "**AS THE REGION_POPULATION_RELATIVE AND AMT_TOTAL_INCOME increases the no of defaults decreases hence it has a negative correlation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.CONTI-CATEGORICAL ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Conti-Categorical\n",
    "plt.figure(figsize = (15, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.boxplot(x = \"CODE_GENDER\", y = 'AMT_CREDIT', data = df_1)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non Default\")\n",
    "sns.boxplot(x = \"CODE_GENDER\", y = 'AMT_CREDIT', data = df_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Conti-Categorical\n",
    "plt.figure(figsize = (15, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.boxplot(x = \"Income_Bucket\", y = 'AMT_CREDIT', data = df_1)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non Default\")\n",
    "sns.boxplot(x = \"Income_Bucket\", y = 'AMT_CREDIT', data = df_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION**-As the value of Income increases the value of Amount CREDIT also increases thus giving us the above insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.CATEGORICAL-CATEGORICAL ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Categorical-Categorical\n",
    "plt.figure(figsize = (15, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(x = \"Income_Bucket\", hue = 'CODE_GENDER', data = df_1)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non Default\")\n",
    "sns.countplot(x = \"Income_Bucket\", hue = 'CODE_GENDER', data = df_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Categorical-Categorical\n",
    "plt.figure(figsize = (17, 8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(x = \"CODE_GENDER\", hue = 'NAME_TYPE_SUITE', data = df_1)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non Default\")\n",
    "sns.countplot(x = \"CODE_GENDER\", hue = 'NAME_TYPE_SUITE', data = df_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Categorical-Categorical\n",
    "plt.figure(figsize = (17, 8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(x = \"NAME_FAMILY_STATUS\", hue = 'NAME_EDUCATION_TYPE', data = df_1)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non Default\")\n",
    "sns.countplot(x = \"NAME_FAMILY_STATUS\", hue = 'NAME_EDUCATION_TYPE', data = df_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - An unmarried customer with higher education is less likely to default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Categorical-Categorical\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(x = \"Income_Bucket\", hue = 'WEEKDAY_APPR_PROCESS_START', data = df_1)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non Default\")\n",
    "sns.countplot(x = \"Income_Bucket\", hue = 'WEEKDAY_APPR_PROCESS_START', data = df_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Categorical-Categorical\n",
    "plt.figure(figsize = (15, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(x = \"NAME_CONTRACT_TYPE\", hue = 'FLAG_OWN_REALTY', data = df_1)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Non Default\")\n",
    "sns.countplot(x = \"NAME_CONTRACT_TYPE\", hue = 'FLAG_OWN_REALTY', data = df_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EXPLORING PREVIOUS APP DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PART-1 CLEANING AND ANALYSIS OF DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Taking 40% Sample of the data for previous data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "num_lines=sum(1 for i in open(\"./data/previous_application.csv\"))\n",
    "num_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=round(num_lines*0.6)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=random.sample(range(1,num_lines),size)\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev=pd.read_csv(\"./data/previous_application.csv\",skiprows=ids)\n",
    "df_prev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 100*df_prev.isnull().sum().sort_values()/df_prev.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DROPPING columns which have null values more than 40%\n",
    "columns_incl = x[x<40].index\n",
    "columns_incl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev1=df_prev.loc[:,columns_incl]\n",
    "df_prev1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MERGING THE 2 DATASETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev1.SK_ID_CURR.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev1.SK_ID_CURR = df_prev1.SK_ID_CURR.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2=pd.merge(df_prev1,df,left_on='SK_ID_CURR',right_on='SK_ID_CURR',how='inner')\n",
    "df_merge2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*df_merge2.isnull().sum()/df_merge2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dropping all rows with missing values (except EXT_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2 = df_merge2[~df_merge2[\"Num-Children\"].isnull()]                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2 = df_merge2[~df_merge2[\"Size_Family\"].isnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2 = df_merge2[~df_merge2[\"AMT_CREDIT_x\"].isnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2 = df_merge2[~df_merge2[\"PRODUCT_COMBINATION\"].isnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2 = df_merge2[~df_merge2[\"CNT_PAYMENT\"].isnull()] \n",
    "df_merge2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merge2 = df_merge2[~df_merge2[\"AMT_ANNUITY_x\"].isnull()] \n",
    "df_merge2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2 = df_merge2[~df_merge2[\"AMT_GOODS_PRICE_x\"].isnull()] \n",
    "df_merge2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*df_merge2.isnull().sum()/df_merge2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONVERTING AGE TO YEARS FOR DAYS_DECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2['DAYS_DECISION'] = abs(df_merge2['DAYS_DECISION'])/365\n",
    "df_merge2['DAYS_DECISION'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping the outliers for easier analyis\n",
    "def calc_iqr(x):\n",
    "    Q1 = df_merge2[x].quantile(0.25)\n",
    "    Q3 = df_merge2[x].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return Q3+1.5*IQR\n",
    "len(df_merge2.AMT_GOODS_PRICE_x[(df_merge2.AMT_GOODS_PRICE_x > 2*calc_iqr('AMT_GOODS_PRICE_x'))])\n",
    "\n",
    "\n",
    "df_merge2=df_merge2[df_merge2.AMT_GOODS_PRICE_x<2*calc_iqr('AMT_GOODS_PRICE_x')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PART 2.CORRELATION AND TOP 10 VARIABLES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouping similar variable together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2 = df_merge2[['SK_ID_PREV','SK_ID_CURR',\n",
    "        'NAME_CONTRACT_STATUS','TARGET', 'EXT_SOURCE_1', 'EXT_SOURCE_2','EXT_SOURCE_3','CODE_REJECT_REASON', 'DAYS_DECISION', \n",
    "        'AMT_INCOME_TOTAL',  'AMT_ANNUITY_x','AMT_GOODS_PRICE_x','AMT_APPLICATION','AMT_CREDIT_x','AMT_CREDIT_y','AMT_ANNUITY_y', 'AMT_GOODS_PRICE_y',\n",
    "       'NAME_CONTRACT_TYPE_x', 'NAME_CONTRACT_TYPE_y', 'NAME_YIELD_GROUP',\n",
    "         'NAME_CASH_LOAN_PURPOSE', 'NAME_PAYMENT_TYPE',               \n",
    "        'NAME_SELLER_INDUSTRY','SELLERPLACE_AREA', 'CHANNEL_TYPE', 'NAME_PRODUCT_TYPE',\n",
    "       'NAME_PORTFOLIO', 'NAME_GOODS_CATEGORY', 'NAME_CLIENT_TYPE',      \n",
    "       'NFLAG_LAST_APPL_IN_DAY', 'FLAG_LAST_APPL_PER_CONTRACT',\n",
    "       'HOUR_APPR_PROCESS_START_x', 'WEEKDAY_APPR_PROCESS_START_x',\n",
    "       'PRODUCT_COMBINATION', 'CNT_PAYMENT', 'CODE_GENDER',\n",
    "       'NAME_EDUCATION_TYPE', 'ORGANIZATION_TYPE', 'OCCUPATION_TYPE',\n",
    "       'NAME_INCOME_TYPE', 'NAME_FAMILY_STATUS', 'CNT_FAM_MEMBERS',\n",
    "       'CNT_CHILDREN', 'FLAG_OWN_REALTY',\n",
    "       'NAME_HOUSING_TYPE', 'FLAG_OWN_CAR', 'REGION_POPULATION_RELATIVE',\n",
    "       'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY',\n",
    "       'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "       'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "       'WEEKDAY_APPR_PROCESS_START_y', 'HOUR_APPR_PROCESS_START_y',\n",
    "       'NAME_TYPE_SUITE', 'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "       'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "       'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "       'AMT_REQ_CREDIT_BUREAU_YEAR', 'AGE', 'YRS_EMPLOYED',\n",
    "       'Hourly_Bucket', 'Age_Bucket', 'Income_Bucket', 'Num-Children',\n",
    "       'Size_Family']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge3 = df_merge2.loc[:,['NAME_CONTRACT_STATUS','TARGET', 'EXT_SOURCE_1', 'EXT_SOURCE_2','EXT_SOURCE_3','DAYS_DECISION','CNT_FAM_MEMBERS',\n",
    "       'CNT_CHILDREN', 'REGION_POPULATION_RELATIVE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "       'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE','AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "       'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "       'AMT_REQ_CREDIT_BUREAU_YEAR','NAME_CONTRACT_TYPE_x', 'NAME_CONTRACT_TYPE_y','NAME_SELLER_INDUSTRY','CHANNEL_TYPE',\n",
    "          'NAME_CLIENT_TYPE', 'NAME_YIELD_GROUP', 'FLAG_OWN_CAR','NAME_PORTFOLIO',  'AGE', 'YRS_EMPLOYED',\n",
    "        'AMT_INCOME_TOTAL',  'AMT_ANNUITY_x','AMT_GOODS_PRICE_x','AMT_APPLICATION','AMT_CREDIT_x','AMT_CREDIT_y','AMT_ANNUITY_y', 'AMT_GOODS_PRICE_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SPLITTING THE DATASETS INTO 3 PARTS ON THE BASIS OF CONTRACT_STATUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_appr=df_merge3[df_merge3.NAME_CONTRACT_STATUS=='Approved']\n",
    "df_canc=df_merge3[df_merge3.NAME_CONTRACT_STATUS=='Canceled']\n",
    "df_refu=df_merge3[df_merge3.NAME_CONTRACT_STATUS=='Refused']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_appr.corr()\n",
    "corr_df_1 = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "corr_df_1 = corr_df_1.unstack().reset_index().dropna(subset = [0])\n",
    "corr_df_1.columns = ['VAR1', 'VAR2', 'Correlation_Value']\n",
    "corr_df_1['Corr_abs'] = abs(corr_df_1['Correlation_Value'])\n",
    "corr_df_1.sort_values(by = \"Corr_abs\", ascending =False, inplace = True)\n",
    "corr_df_1.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_refu.corr()\n",
    "corr_df_1 = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "corr_df_1 = corr_df_1.unstack().reset_index().dropna(subset = [0])\n",
    "corr_df_1.columns = ['VAR1', 'VAR2', 'Correlation_Value']\n",
    "corr_df_1['Corr_abs'] = abs(corr_df_1['Correlation_Value'])\n",
    "corr_df_1.sort_values(by = \"Corr_abs\", ascending =False, inplace = True)\n",
    "corr_df_1.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PART 3.UNIVARIATE AND BIVARIATE ANALYSIS ON MERGED DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.UNIVARIATE-CONTINUOUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,10])\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Approved\")\n",
    "sns.boxplot(df_appr.AMT_GOODS_PRICE_x)\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Cancelled\")\n",
    "sns.boxplot(df_canc.AMT_GOODS_PRICE_x)\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Refused\")\n",
    "sns.boxplot(df_refu.AMT_GOODS_PRICE_x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,8])\n",
    "sns.distplot(df_appr.AMT_APPLICATION, hist = False, label = 'Approved')\n",
    "sns.distplot(df_refu.AMT_APPLICATION, hist = False, label = 'Refused')\n",
    "sns.distplot(df_canc.AMT_APPLICATION, hist = False, label = 'Cancelled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - The above 2 graphs suggest strongly that the probablity of approving a loan is higher if the Loan amount applied for is below 200000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,6])\n",
    "plt.subplot(1,3,1)\n",
    "sns.distplot(df_appr.EXT_SOURCE_1, hist = False, label = 'Approved')\n",
    "sns.distplot(df_refu.EXT_SOURCE_1, hist = False, label = 'Refused')\n",
    "sns.distplot(df_canc.EXT_SOURCE_1, hist = False, label = 'Cancelled')\n",
    "plt.subplot(1,3,2)\n",
    "sns.distplot(df_appr.EXT_SOURCE_2, hist = False, label = 'Approved')\n",
    "sns.distplot(df_refu.EXT_SOURCE_2, hist = False, label = 'Refused')\n",
    "sns.distplot(df_canc.EXT_SOURCE_2, hist = False, label = 'Cancelled')\n",
    "plt.subplot(1,3,3)\n",
    "sns.distplot(df_appr.EXT_SOURCE_3, hist = False, label = 'Approved')\n",
    "sns.distplot(df_refu.EXT_SOURCE_3, hist = False, label = 'Refused')\n",
    "sns.distplot(df_canc.EXT_SOURCE_3, hist = False, label = 'Cancelled')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=[12,6])\n",
    "sns.distplot(df_appr.DAYS_DECISION, hist = False, label = 'Approved')\n",
    "sns.distplot(df_refu.DAYS_DECISION, hist = False, label = 'Refused')\n",
    "sns.distplot(df_canc.DAYS_DECISION, hist = False, label = 'Cancelled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - It doesn't take a long time to cancel a loan request, but this bank take usually more than 2 days to approve a loan, there is also a risk of the customer cancelling the request in that period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.UNIVAR-CATEGORICAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,6])\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "x=df_merge3[df_merge3.TARGET=='Yes']\n",
    "plt.title(\"Default\")\n",
    "sns.countplot(x['NAME_CONTRACT_STATUS'])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "y=df_merge3[df_merge3.TARGET=='No']\n",
    "plt.title(\"Non-Default\")\n",
    "sns.countplot(y['NAME_CONTRACT_STATUS'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Approved\")\n",
    "sns.countplot(df_appr['NAME_CONTRACT_TYPE_x'])\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Refused\")\n",
    "sns.countplot(df_refu['NAME_CONTRACT_TYPE_x'])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Cancelled\")\n",
    "sns.countplot(df_canc['NAME_CONTRACT_TYPE_x'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - From the above metric we can see that mostly **Consumer Loans are approved** and **Cash Loans are rejected** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Approved\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_appr['NAME_SELLER_INDUSTRY'])\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Refused\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_refu['NAME_SELLER_INDUSTRY'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** -Most of the loans approved belongs to the data where Selling industry is **Consumer Electronics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(df_merge3['CHANNEL_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** -Top channels through which they acquired the client on the previous application :\n",
    "- Credit and cash offices : 43 % times\n",
    "- Country_wide : 30 % times\n",
    "- Stone : 13 % times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.BIVARIATE-CONTI-CONTI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter\n",
    "\n",
    "plt.figure(figsize = (16, 8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Approved\")\n",
    "sns.lineplot(x='AMT_GOODS_PRICE_x',y='AMT_CREDIT_x',data=df_appr)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Refused\")\n",
    "sns.lineplot(df_refu['AMT_GOODS_PRICE_x'], df_refu['AMT_CREDIT_x'])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Cancelled\")\n",
    "sns.lineplot(df_canc['AMT_GOODS_PRICE_x'], df_canc['AMT_CREDIT_x'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.BIVARIATE-CONTI-CATEGORICAL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Continuous-Categorical\n",
    "plt.figure(figsize = (20, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Approved\")\n",
    "sns.boxplot(x = \"TARGET\", y = 'DAYS_DECISION', data = df_appr)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Refused\")\n",
    "sns.boxplot(x = \"TARGET\", y = 'DAYS_DECISION', data = df_refu)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Cancelled\")\n",
    "sns.boxplot(x = \"TARGET\", y = 'DAYS_DECISION', data = df_canc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Continuous-Categorical\n",
    "plt.figure(figsize = (20, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Approved\")\n",
    "sns.boxplot(x = \"NAME_PORTFOLIO\", y = 'AMT_CREDIT_x', data = df_appr)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Refused\")\n",
    "sns.boxplot(x = \"NAME_PORTFOLIO\", y = 'AMT_CREDIT_x', data = df_refu)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Cancelled\")\n",
    "sns.boxplot(x = \"NAME_PORTFOLIO\", y = 'AMT_CREDIT_x', data = df_canc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - The maximum amount of credit loans were taken for the NAME_PORTFOLIO as \"CASH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Continuous-Categorical\n",
    "plt.figure(figsize = (20, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Approved\")\n",
    "sns.boxplot(x = \"NAME_CLIENT_TYPE\", y = 'DAYS_DECISION', data = df_appr)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Refused\")\n",
    "sns.boxplot(x = \"NAME_CLIENT_TYPE\", y = 'DAYS_DECISION', data = df_refu)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Cancelled\")\n",
    "sns.boxplot(x = \"NAME_CLIENT_TYPE\", y = 'DAYS_DECISION', data = df_canc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - New CLients have a higher number of decision days in comparison to the older clients ie for newer clients the the relative time taken for a decision on previous application is much higher than the older clients as they may be involved in paperworks and other parameters which may impact their loan approval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.BIVARIATE-CATEGORICAL-CATEGORICAL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Categorical-Categorical\n",
    "plt.figure(figsize = (16, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Approved\")\n",
    "sns.countplot(x = \"TARGET\", hue = 'NAME_CONTRACT_TYPE_x', data = df_appr)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Refused\")\n",
    "sns.countplot(x = \"TARGET\", hue = 'NAME_CONTRACT_TYPE_x', data = df_refu)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Cancelled\")\n",
    "sns.countplot(x = \"TARGET\", hue = 'NAME_CONTRACT_TYPE_x', data = df_canc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION** - \n",
    "- From the above analysis we can see that people who have approved previous loans and belong to the category of consumer loans tend to default the maximum.\n",
    "- People who have been refused previous loans and have taken cash loans tends to belong to non-default category. A possible reason may be they have been rejected a loan multiple times and hence once they get the loan they will not be willing to take a risk to come under defaulter category and hence get rejected again in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Categorical-Categorical\n",
    "plt.figure(figsize = (20, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Approved\")\n",
    "sns.countplot(x = \"TARGET\", hue = 'NAME_YIELD_GROUP', data = df_appr)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Refused\")\n",
    "sns.countplot(x = \"TARGET\", hue = 'NAME_YIELD_GROUP', data = df_refu)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Cancelled\")\n",
    "sns.countplot(x = \"TARGET\", hue = 'NAME_YIELD_GROUP', data = df_canc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate - Categorical-Categorical\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Approved\")\n",
    "sns.countplot(x = \"TARGET\", hue = 'FLAG_OWN_CAR', data = df_appr)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Refused\")\n",
    "sns.countplot(x = \"TARGET\", hue = 'FLAG_OWN_CAR', data = df_refu)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Cancelled\")\n",
    "sns.countplot(x = \"TARGET\", hue = 'FLAG_OWN_CAR', data = df_canc)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
